{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq + E2B MCP Gateway: Multiple MCP Servers in One Sandbox\n",
    "\n",
    "This notebook demonstrates how to use E2B's MCP Gateway to run multiple Model Context Protocol servers together with Groq's ultra-fast inference.\n",
    "\n",
    "## What is E2B MCP Gateway?\n",
    "\n",
    "E2B's MCP Gateway provides a unified interface to multiple MCP servers running inside an isolated sandbox. Instead of connecting to each MCP server separately, you get:\n",
    "\n",
    "- **One endpoint** for all your MCP tools (Exa, Browserbase, Notion, etc.)\n",
    "- **Isolated environment** where MCPs run securely\n",
    "- **Seamless integration** with Groq's Responses API\n",
    "- **200+ tools** from the Docker MCP Catalog\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "We'll create an AI research agent that:\n",
    "1. **Searches** for AI companies using Exa MCP's web search\n",
    "2. **Visits** their websites using Browserbase MCP's browser automation\n",
    "3. **Extracts** pricing and contact information\n",
    "4. **Returns** structured results‚Äîall through one E2B gateway\n",
    "\n",
    "This showcases how E2B makes it trivial to combine multiple MCP capabilities in a single workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You'll need API keys from four services:\n",
    "\n",
    "1. **E2B** ([e2b.dev](https://e2b.dev/)) - Provides the unified MCP gateway and sandbox\n",
    "2. **Browserbase** ([browserbase.com](https://www.browserbase.com/)) - Browser automation MCP\n",
    "   - You'll need both an API key AND a Project ID\n",
    "3. **Exa** ([dashboard.exa.ai](https://dashboard.exa.ai/api-keys)) - Web search MCP\n",
    "4. **Groq** ([console.groq.com](https://console.groq.com/keys)) - Ultra-fast LLM inference\n",
    "\n",
    "### Set Environment Variables\n",
    "\n",
    "After obtaining your API keys, set them as environment variables:\n",
    "\n",
    "**macOS/Linux:**\n",
    "```bash\n",
    "export E2B_API_KEY='your_e2b_key'\n",
    "export BROWSERBASE_API_KEY='your_browserbase_key'\n",
    "export BROWSERBASE_PROJECT_ID='your_project_id'\n",
    "export EXA_API_KEY='your_exa_key'\n",
    "export GROQ_API_KEY='your_groq_key'\n",
    "```\n",
    "\n",
    "**Windows (PowerShell):**\n",
    "```powershell\n",
    "$Env:E2B_API_KEY='your_e2b_key'\n",
    "$Env:BROWSERBASE_API_KEY='your_browserbase_key'\n",
    "$Env:BROWSERBASE_PROJECT_ID='your_project_id'\n",
    "$Env:EXA_API_KEY='your_exa_key'\n",
    "$Env:GROQ_API_KEY='your_groq_key'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install e2b==2.4.0 openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Configure API Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from e2b import Sandbox\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API keys from environment\n",
    "E2B_API_KEY = os.getenv(\"E2B_API_KEY\")\n",
    "BROWSERBASE_API_KEY = os.getenv(\"BROWSERBASE_API_KEY\")\n",
    "BROWSERBASE_PROJECT_ID = os.getenv(\"BROWSERBASE_PROJECT_ID\")\n",
    "EXA_API_KEY = os.getenv(\"EXA_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Validate API keys\n",
    "missing_keys = []\n",
    "if not E2B_API_KEY:\n",
    "    missing_keys.append(\"E2B_API_KEY\")\n",
    "if not BROWSERBASE_API_KEY:\n",
    "    missing_keys.append(\"BROWSERBASE_API_KEY\")\n",
    "if not BROWSERBASE_PROJECT_ID:\n",
    "    missing_keys.append(\"BROWSERBASE_PROJECT_ID\")\n",
    "if not EXA_API_KEY:\n",
    "    missing_keys.append(\"EXA_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    missing_keys.append(\"GROQ_API_KEY\")\n",
    "\n",
    "if missing_keys:\n",
    "    print(\"‚ùå Missing required API keys:\")\n",
    "    for key in missing_keys:\n",
    "        print(f\"   - {key}\")\n",
    "    print(\"\\nPlease set all required environment variables before continuing.\")\n",
    "else:\n",
    "    print(\"‚úÖ All API keys configured successfully!\")\n",
    "    print(\"   - E2B API key\")\n",
    "    print(\"   - Browserbase API key + Project ID\")\n",
    "    print(\"   - Exa API key\")\n",
    "    print(\"   - Groq API key\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL = \"openai/gpt-oss-120b\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create E2B Sandbox with MCP Gateway\n",
    "\n",
    "Here's where the magic happens. We create a single E2B sandbox that hosts both Exa and Browserbase MCP servers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Creating E2B sandbox with MCP gateway...\")\n",
    "start = time.time()\n",
    "\n",
    "# Create sandbox with multiple MCP servers configured\n",
    "sandbox = Sandbox.create(\n",
    "    api_key=E2B_API_KEY,\n",
    "    mcp={\n",
    "        'browserbase': {\n",
    "            'apiKey': BROWSERBASE_API_KEY,\n",
    "            'projectId': BROWSERBASE_PROJECT_ID,\n",
    "        },\n",
    "        'exa': {\n",
    "            'apiKey': EXA_API_KEY,\n",
    "        }\n",
    "    },\n",
    "    timeout=600\n",
    ")\n",
    "\n",
    "# Get the unified gateway URL and authentication token\n",
    "mcp_url = sandbox.get_mcp_url()\n",
    "mcp_token = sandbox.get_mcp_token()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"‚úÖ Sandbox created in {elapsed:.2f}s\")\n",
    "print(f\"   Gateway URL: {mcp_url}\")\n",
    "print(f\"   Sandbox Info: {sandbox.get_info()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup Groq Client\n",
    "\n",
    "Initialize the Groq client using OpenAI's SDK (Groq is OpenAI-compatible):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/api/openai/v1\",\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Groq client initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure MCP Tools for Groq\n",
    "\n",
    "Tell Groq about the E2B MCP gateway. Notice we only need ONE tool configuration‚ÄîE2B routes to all MCPs internally:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_url\": mcp_url,\n",
    "        \"server_label\": \"e2b-gateway\",\n",
    "        \"require_approval\": \"never\",\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {mcp_token}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ MCP tools configured for Groq\")\n",
    "print(f\"   Using unified E2B gateway at: {mcp_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Function: Research with Multiple MCPs\n",
    "\n",
    "This function demonstrates the power of E2B's unified gateway:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_companies_with_e2b(query, client, tools):\n",
    "    \"\"\"\n",
    "    Research companies using multiple MCP servers through E2B's unified gateway.\n",
    "    \n",
    "    This function demonstrates:\n",
    "    - Exa MCP for web search\n",
    "    - Browserbase MCP for browser automation\n",
    "    - All through one E2B gateway endpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Research Query: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Call Groq with E2B MCP gateway\n",
    "    # The LLM will automatically use Exa and Browserbase as needed\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "        tools=tools,\n",
    "        stream=False,\n",
    "        temperature=0.1,\n",
    "        top_p=0.4,\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Extract response content\n",
    "    content = response.output_text if hasattr(response, \"output_text\") else str(response)\n",
    "    \n",
    "    # Collect executed MCP calls\n",
    "    executed_tools = []\n",
    "    exa_calls = 0\n",
    "    browserbase_calls = 0\n",
    "    \n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"type\") and output_item.type == \"mcp_call\":\n",
    "                tool_info = {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"name\": getattr(output_item, \"name\", \"\"),\n",
    "                    \"server_label\": getattr(output_item, \"server_label\", \"\"),\n",
    "                    \"arguments\": getattr(output_item, \"arguments\", \"{}\"),\n",
    "                }\n",
    "                executed_tools.append(tool_info)\n",
    "                \n",
    "                # Count calls by MCP server\n",
    "                tool_name = tool_info[\"name\"].lower()\n",
    "                if \"exa\" in tool_name or \"search\" in tool_name:\n",
    "                    exa_calls += 1\n",
    "                elif \"browserbase\" in tool_name or \"stagehand\" in tool_name:\n",
    "                    browserbase_calls += 1\n",
    "    \n",
    "    return {\n",
    "        \"content\": content,\n",
    "        \"total_time\": total_time,\n",
    "        \"mcp_calls_performed\": executed_tools,\n",
    "        \"exa_calls\": exa_calls,\n",
    "        \"browserbase_calls\": browserbase_calls,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }\n",
    "\n",
    "\n",
    "def print_research_results(result):\n",
    "    \"\"\"\n",
    "    Pretty-print research results showing which MCPs were used.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RESEARCH RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result[\"content\"])\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show MCP usage\n",
    "    executed_tools = result[\"mcp_calls_performed\"]\n",
    "    if executed_tools:\n",
    "        print(f\"\\nüîß MCP CALLS: {len(executed_tools)} tool calls executed\")\n",
    "        print(f\"   üì° Exa calls: {result['exa_calls']}\")\n",
    "        print(f\"   üåê Browserbase calls: {result['browserbase_calls']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, tool in enumerate(executed_tools, 1):\n",
    "            print(f\"\\n   Call #{i}: {tool['name']}\")\n",
    "            print(f\"   Server: {tool['server_label']}\")\n",
    "            \n",
    "            # Parse and display arguments\n",
    "            try:\n",
    "                args = json.loads(tool[\"arguments\"]) if isinstance(tool[\"arguments\"], str) else tool[\"arguments\"]\n",
    "                print(f\"   Arguments: {json.dumps(args, indent=6)[:200]}...\")\n",
    "            except:\n",
    "                print(f\"   Arguments: {str(tool['arguments'])[:200]}...\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  PERFORMANCE\")\n",
    "    print(f\"   Total time: {result['total_time']:.2f}s\")\n",
    "    print(f\"   MCP calls: {len(executed_tools)}\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Research AI Inference Companies\n",
    "\n",
    "Let's research AI companies that provide inference APIs and extract their pricing information.\n",
    "\n",
    "Watch how the agent:\n",
    "1. Uses **Exa** to search for AI inference companies\n",
    "2. Uses **Browserbase** to visit their websites\n",
    "3. Extracts pricing and contact details\n",
    "\n",
    "All of this happens through the **single E2B gateway** we configured:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = research_companies_with_e2b(\n",
    "    \"Find 2 AI inference API companies and get their pricing information from their websites\",\n",
    "    client,\n",
    "    tools\n",
    ")\n",
    "\n",
    "print_research_results(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the response in markdown format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(result1[\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Custom Research Task\n",
    "\n",
    "Now it's your turn! Replace the query below with your own research task.\n",
    "\n",
    "Ideas to try:\n",
    "- \"Find popular AI image generation tools and check their pricing\"\n",
    "- \"Research vector database companies and extract their key features\"\n",
    "- \"Find AI agent frameworks and get their documentation links\"\n",
    "- \"Research LLM observability tools and compare their features\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_query = \"Your research query here\"  # Change this!\n",
    "\n",
    "result2 = research_companies_with_e2b(\n",
    "    custom_query,\n",
    "    client,\n",
    "    tools\n",
    ")\n",
    "\n",
    "print_research_results(result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've seen E2B's MCP gateway in action, here are some ideas to explore:\n",
    "\n",
    "### Add More MCP Servers\n",
    "E2B supports 200+ MCP servers from the Docker MCP Catalog. Try adding:\n",
    "- **Notion** - Store research findings in a database\n",
    "- **Airtable** - Organize data in spreadsheets\n",
    "- **GitHub** - Search code repositories\n",
    "- **Slack** - Send notifications\n",
    "- **Firecrawl** - Advanced web scraping\n",
    "\n",
    "Just add them to the `mcp` configuration:\n",
    "```python\n",
    "sandbox = Sandbox.create(\n",
    "    mcp={\n",
    "        'browserbase': {...},\n",
    "        'exa': {...},\n",
    "        'notion': {\n",
    "            'internalIntegrationToken': NOTION_API_KEY,\n",
    "        },\n",
    "        # Add more...\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### Build Production Workflows\n",
    "- Create scheduled research jobs that run daily\n",
    "- Build a research API endpoint\n",
    "- Set up monitoring and alerting\n",
    "- Store results in a database\n",
    "\n",
    "### Scale with Multiple Sandboxes\n",
    "- Run parallel research tasks in separate sandboxes\n",
    "- Implement rate limiting and queuing\n",
    "- Add retry logic and error handling\n",
    "\n",
    "### Experiment with Different Models\n",
    "Try different Groq models for different tasks:\n",
    "- `llama-3.3-70b-versatile` - Great for general tasks\n",
    "- `qwen/qwen3-32b` - Fast and efficient\n",
    "- `openai/gpt-oss-120b` - Powerful reasoning\n",
    "\n",
    "### Optimize for Speed\n",
    "- Use streaming responses for real-time updates\n",
    "- Batch similar requests together\n",
    "- Cache frequently accessed data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### E2B MCP Gateway\n",
    "- **Documentation**: [e2b.dev/docs/mcp](https://e2b.dev/docs/mcp)\n",
    "- **Quickstart**: [e2b.dev/docs/mcp/quickstart](https://e2b.dev/docs/mcp/quickstart)\n",
    "- **Available Servers**: [e2b.dev/docs/mcp/available-servers](https://e2b.dev/docs/mcp/available-servers)\n",
    "- **Custom Servers**: [e2b.dev/docs/mcp/custom-servers](https://e2b.dev/docs/mcp/custom-servers)\n",
    "- **GitHub**: [github.com/e2b-dev/e2b](https://github.com/e2b-dev/e2b)\n",
    "\n",
    "### MCP Servers Used\n",
    "- **Exa MCP**: [docs.exa.ai/reference/exa-mcp](https://docs.exa.ai/reference/exa-mcp)\n",
    "- **Exa GitHub**: [github.com/exa-labs/exa-mcp-server](https://github.com/exa-labs/exa-mcp-server)\n",
    "- **Browserbase MCP**: [smithery.ai/server/@browserbasehq/mcp-browserbase](https://smithery.ai/server/@browserbasehq/mcp-browserbase)\n",
    "- **Stagehand Docs**: [docs.stagehand.dev](https://docs.stagehand.dev/)\n",
    "\n",
    "### Groq\n",
    "- **API Documentation**: [console.groq.com/docs](https://console.groq.com/docs)\n",
    "- **Models**: [console.groq.com/docs/models](https://console.groq.com/docs/models)\n",
    "- **Cookbook**: [github.com/groq/groq-api-cookbook](https://github.com/groq/groq-api-cookbook)\n",
    "\n",
    "### Model Context Protocol\n",
    "- **Official Site**: [modelcontextprotocol.io](https://modelcontextprotocol.io)\n",
    "- **Specification**: [spec.modelcontextprotocol.io](https://spec.modelcontextprotocol.io)\n",
    "- **GitHub**: [github.com/modelcontextprotocol](https://github.com/modelcontextprotocol)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy researching with E2B + Groq! üöÄ**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
