{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq + Box MCP: Real-Time, Fast Document Intelligence\n",
    "This notebook is designed for Python developers who want to securely enrich Groq's fast inference with private context retrieved via [Box's MCP Server](https://developer.box.com/guides/box-mcp/) functionality.\n",
    "\n",
    "We will achieve this through three simple steps:\n",
    "1. Set up **Groq client** for fast inference.\n",
    "2. Connect to the **Remote Box MCP Server** to securely search through private content in Box.\n",
    "3. Seemlessly **connect the Groq client to the remove MCP server** through the Responses API.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This cookbook assumes you have:\n",
    "1. A Box **developer** account. If you don't have one, you can sign up for a free account at [box](https://account.box.com/signup/n/developer).\n",
    "2. If you want to run this notebook from Google Colab or other, skip the following. If instead you want to run this locally, make sure you have Python >3.10 installed (3.12 recommended). Create a virtual environment with `python -m venv .venv`. Activate this virtual env as `source .venv/bin/activate`\n",
    "3. Run `pip install -r requirements.txt` from the `mcp-box` folder in `tutorials/`.\n",
    "4. If you are running this locally, also run `pip install jupyter ipykernel`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "If you've gone through the pre-requisites, follow these steps to get set up:\n",
    "1. **Create a Platform App** in the [Box Developer Console](https://app.box.com/developers/console) and enable it. (NOTE - if you have a developer account, you should see \"Box DEVELOPER\" in the top-left). The following process is a little tedious but it's only a one-time thing.\n",
    "\n",
    "    1. Select `Custom App`.\n",
    "    2. Enter an app name. For purpose, select `Automation`.\n",
    "    3. For authentication method, select the option called `Server Authentication (Client Credentials Grant)\n",
    "    4. Click on the created platform app. This is where you will later be able to fetch the `Client ID`, `Client Secret`, and configure anything for your app.\n",
    "    5. From this menu, select the `Configuration` tab. In `App Access Level`, select `App + Enterprise Access`. Save changes.\n",
    "    6. Click on the `Authorization` tab. Here click on `Review and Submit`. \n",
    "    7. You'll now have to head to the `Admin Console` to authorize the app. This [link](https://app.box.com/master/platform-apps) should take you directly there. It should say `Pending Authorization`. Go ahead and authorize it.\n",
    "    8. Go back to the dev console, and open the app you just created. This [link](https://app.box.com/developers/console) should list the app.\n",
    "    9. From the app's general settings tab, copy the `Enterprise ID`. From the configuration tab, copy the `Client ID` and `Client Secret` (might require you to click fetch). Use these values to set environment values for all of these before running the notebook.\n",
    "\n",
    "```\n",
    "export BOX_CLIENT_ID=<value>\n",
    "export BOX_CLIENT_SECRET=<value>\n",
    "export BOX_ENTERPRISE_ID=<value>\n",
    "```\n",
    "\n",
    "2. **Sign up** for Groq at [console.groq.com](https://console.groq.com/keys) to get your free API key. Once you have the API key set the environment variable `GROQ_API_KEY` with its value.\n",
    "\n",
    "```\n",
    "export GROQ_API_KEY=<value>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from box_sdk_gen import (\n",
    "    BoxClient,\n",
    "    BoxCCGAuth,\n",
    "    CCGConfig,\n",
    ")\n",
    "\n",
    "BOX_CLIENT_ID = os.getenv(\"BOX_CLIENT_ID\", \"<value>\")\n",
    "BOX_CLIENT_SECRET = os.getenv(\"BOX_CLIENT_SECRET\", \"<value>\")\n",
    "BOX_ENTERPRISE_ID = os.getenv(\"BOX_ENTERPRISE_ID\", \"<value>\")\n",
    "\n",
    "ccg_config = CCGConfig(\n",
    "    client_id=BOX_CLIENT_ID,\n",
    "    client_secret=BOX_CLIENT_SECRET,\n",
    "    enterprise_id=BOX_ENTERPRISE_ID,\n",
    ")\n",
    "auth = BoxCCGAuth(config=ccg_config)\n",
    "box_client = BoxClient(auth=auth)\n",
    "\n",
    "BOX_MCP_TOKEN = box_client.auth.retrieve_token().access_token\n",
    "# To run locally you can also just set the token directly \n",
    "# this can be generated from the developer console\n",
    "# comment out the line above and uncomment the line below\n",
    "# BOX_MCP_TOKEN = \"<value>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Groq API Configuration\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if API key is set\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Please set your Groq production API key\")\n",
    "else:\n",
    "    print(\"Groq API key configured successfully!\")\n",
    "if not BOX_MCP_TOKEN:\n",
    "    print(\"Please set your Box Developer Token\")\n",
    "else:\n",
    "    print(\"Box Developer Token configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the foundation model to power inference. Let's try OpenAI's flagship open-weights MoE model, [gpt-oss-120b](https://console.groq.com/docs/model/openai/gpt-oss-120b), available via Groq for fast inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will upload all files that are stored in the `data` folder by default. If you'd like to try out with your own data, please add some data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "BOX_PARENT_FOLDER_NAME = \"groq-cookbook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATA_FOLDER)\n",
    "if not files:\n",
    "    raise ValueError(f\"No files to upload. Please add some data to the {DATA_FOLDER} folder.\")\n",
    "print(\"Files to be uploaded:\")\n",
    "print(\"-\" * 50)\n",
    "files_to_upload = []\n",
    "for f in files:\n",
    "    print(f)\n",
    "    files_to_upload.append((os.path.join(DATA_FOLDER, f), f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a folder in our Box MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box_sdk_gen import CreateFolderParent\n",
    "\n",
    "ROOT_FOLDER_ID = \"0\"\n",
    "\n",
    "print(f\"Creating folder: {BOX_PARENT_FOLDER_NAME} in Box\")\n",
    "folder = box_client.folders.create_folder(BOX_PARENT_FOLDER_NAME, CreateFolderParent(id=ROOT_FOLDER_ID))\n",
    "\n",
    "parent_folder_id = folder.id\n",
    "parent_folder_name = folder.name\n",
    "print(f\"Created folder with ID: {parent_folder_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are helper functions that you may find useful. You don't need to run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder(client, folder_id, recursive=True):\n",
    "    \"\"\"\n",
    "    Delete the folder with folder_id and all of its contents.\n",
    "    Be careful with this function, it will delete the folder and all of its contents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.folders.delete_folder_by_id(folder_id, recursive=recursive)\n",
    "        print(f\"Deleted folder {folder_id} {'recursively' if recursive else ''} via direct API call\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def list_folders(client, parent_folder_id):\n",
    "    folder_ids = []\n",
    "    items = client.folders.get_folder_items(parent_folder_id)\n",
    "    for entry in items.entries:\n",
    "        if entry.type == 'folder':\n",
    "            folder_ids.append((entry.id, entry.name))\n",
    "    return folder_ids\n",
    "    \n",
    "def list_files(client, parent_folder_id, recursive=False):\n",
    "    file_ids = []\n",
    "    items = client.folders.get_folder_items(parent_folder_id)\n",
    "    for entry in items.entries:\n",
    "        if entry.type == 'file':\n",
    "            file_ids.append((entry.id, entry.name))\n",
    "        elif entry.type == 'folder' and recursive:\n",
    "            file_ids.extend(list_files(client, entry.id, recursive=True))\n",
    "    return file_ids\n",
    "\n",
    "folder_ids = list_folders(box_client, ROOT_FOLDER_ID)\n",
    "print(f\"Found {len(folder_ids)} folders\")\n",
    "print(\"-\" * 50)\n",
    "for folder_id, folder_name in folder_ids:\n",
    "    print(f\"{folder_id} - {folder_name}\")\n",
    "\n",
    "file_ids = list_files(box_client, ROOT_FOLDER_ID, recursive=True)\n",
    "print(f\"Found {len(file_ids)} files\")\n",
    "print(\"-\" * 50)\n",
    "for file_id, file_name in file_ids:\n",
    "    print(f\"{file_id} - {file_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box_sdk_gen import UploadFileAttributes, UploadFileAttributesParentField\n",
    "\n",
    "def upload_data_to_box(client, files, parent_folder_id):\n",
    "    assert isinstance(files, list)\n",
    "    assert isinstance(files[0], tuple), \"files must be a list of tuples (file_path, file_name)\"\n",
    "    successful_uploads = []\n",
    "    for file_path, file_name in files:\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                _ = client.uploads.upload_file(\n",
    "                    UploadFileAttributes(\n",
    "                        name=file_name, parent=UploadFileAttributesParentField(id=parent_folder_id)\n",
    "                    ),\n",
    "                    file,\n",
    "            )\n",
    "            successful_uploads.append(file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading file {file_name}: {e}\")\n",
    "            pass\n",
    "    print(\"Successfully uploaded:\")\n",
    "    print(\"-\" * 50)\n",
    "    for f in successful_uploads:\n",
    "        print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisite 1: Upload data to Box\n",
    "Keep in mind, as mentioned before, we'll upload all files stored in the `data` local folder by default. We have a single sample file there to power this demo. If you'd like to try out with your own data, please add some data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data_to_box(box_client, files_to_upload, parent_folder_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the Groq client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# set up Groq client\n",
    "client = OpenAI(base_url=\"https://api.groq.com/api/openai/v1\", api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up Box's remote MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Box MCP server\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_url\": f\"https://mcp.box.com\",\n",
    "        \"server_label\": \"box\",\n",
    "        \"require_approval\": \"never\",\n",
    "        \"headers\": { \"Authorization\": f\"Bearer {BOX_MCP_TOKEN}\" }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Connect Groq to the Box MCP through Groq's OpenAI-compatible Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_groq_to_box(client, tools, query):\n",
    "    \"\"\"\n",
    "    Connect Groq client to Box server through responses API.\n",
    "\n",
    "    This function demonstrates the speed and accuracy of combining:\n",
    "    - Groq's fast LLM inference (500+ tokens/second)\n",
    "    - Box MCP server for real-time document search and retrieval\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Call Groq with Box MCP integration using responses API\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "        tools=tools,\n",
    "        stream=False,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Get response content from responses API\n",
    "    content = (\n",
    "        response.output_text if hasattr(response, \"output_text\") else str(response)\n",
    "    )\n",
    "\n",
    "    # collect executed tools (MCP tool calls)\n",
    "    executed_tools = []\n",
    "\n",
    "    # Extract MCP calls from response if available\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"type\") and output_item.type == \"mcp_call\":\n",
    "                executed_tools.append(\n",
    "                    {\n",
    "                        \"type\": \"mcp\",\n",
    "                        \"arguments\": getattr(output_item, \"arguments\", \"{}\"),\n",
    "                        \"output\": getattr(output_item, \"output\", \"\"),\n",
    "                        \"name\": getattr(output_item, \"name\", \"\"),\n",
    "                        \"server_label\": getattr(output_item, \"server_label\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "    return {\n",
    "        \"content\": content,\n",
    "        \"total_time\": total_time,\n",
    "        \"mcp_calls_performed\": executed_tools,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a helper function to display MCP tool calls and their results. This will provide transparency into which tools were called, their arguments, and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mcp_calls(mcp_calls):\n",
    "    executed_tools = mcp_calls[\"mcp_calls_performed\"]\n",
    "    if executed_tools:\n",
    "        print(f\"\\nBOX MCP CALLS: Found {len(executed_tools)} tool call(s):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, tool in enumerate(executed_tools, 1):\n",
    "            print(f\"\\nTool Call #{i}\")\n",
    "            print(f\"   Type: {tool['type']}\")\n",
    "            print(f\"   Tool Name: {tool['name']}\")\n",
    "            print(f\"   Server: {tool['server_label']}\")\n",
    "            try:\n",
    "                if tool[\"arguments\"]:\n",
    "                    args = (\n",
    "                        json.loads(tool[\"arguments\"])\n",
    "                        if isinstance(tool[\"arguments\"], str)\n",
    "                        else tool[\"arguments\"]\n",
    "                    )\n",
    "                    print(f\"   Arguments: {args}\")\n",
    "\n",
    "                # Print model results for transparency\n",
    "                if tool[\"output\"]:\n",
    "                    output_data = (\n",
    "                        json.loads(tool[\"output\"])\n",
    "                        if isinstance(tool[\"output\"], str)\n",
    "                        else tool[\"output\"]\n",
    "                    )\n",
    "                    if isinstance(output_data, dict) and \"models\" in output_data:\n",
    "                        print(f\"   Models found: {len(output_data['models'])}\")\n",
    "                        for j, model in enumerate(\n",
    "                            output_data[\"models\"][:5], 1\n",
    "                        ):  # Show top 5\n",
    "                            model_name = model.get(\"id\", model.get(\"name\", \"Unknown\"))\n",
    "                            print(f\"      {j}. {model_name}\")\n",
    "                        if len(output_data[\"models\"]) > 5:\n",
    "                            print(\n",
    "                                f\"      ... and {len(output_data['models']) - 5} more models\"\n",
    "                            )\n",
    "                    else:\n",
    "                        print(f\"   Output: {str(output_data)[:200]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Could not parse tool data: {e}\")\n",
    "    print(f\"   Total time: {mcp_calls['total_time']:.2f} seconds\")\n",
    "    print(f\"   Box MCP calls: {len(mcp_calls['mcp_calls_performed'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "**Note:** Some queries may consume more tokens than others depending on the amount of tool calls the model makes. Please be aware of various rate limits that are tied to your API keys if you happen to run into any rate limit errors. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Let's query a LLM + Box MCP server on AI startup fundraising in SF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# NOTE - we say \"based on private data in my Box account\" just to make it more likely that the MCP server will be used\n",
    "query = \"Summarize the state of AI inference provider (e.g., Groq, Cerebras, SambaNova, etc.) startup fundraising in 2025 based on private data in my Box account\"\n",
    "\n",
    "some_interesting_private_content = connect_groq_to_box(\n",
    "    client,\n",
    "    tools,\n",
    "    query,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the agent's response in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_interesting_private_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(some_interesting_private_content[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the agent's intermediate steps, including how it calls different tools and configures tool arguments such as `search_depth`, `time_range`, `max_results`, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(some_interesting_private_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1.1: Try the same prompt without Box MCP (LLM only)\n",
    "Notice, the LLM will hallucinate fundraising data without access to our private data in Box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"Summarize the state of AI inference provider (e.g., Groq, Cerebras, SambaNova, etc.) startup fundraising in 2025\"\n",
    "\n",
    "some_interesting_private_content = connect_groq_to_box(\n",
    "    client,\n",
    "    [], # NOTE - no tools this time\n",
    "    query,\n",
    ")\n",
    "Markdown(some_interesting_private_content[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Try it Yourself\n",
    "\n",
    "Now it's your turn! Replace the query with something your interested in from your private data in Box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_query = \"Your Query Here\"  # Change this!\n",
    "\n",
    "custom_response = connect_groq_to_box(client, tools, your_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(custom_response[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(custom_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
