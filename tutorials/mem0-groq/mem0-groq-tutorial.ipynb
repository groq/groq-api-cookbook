{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Enabling Mem0 with Groq\n",
    "\n",
    "[**Mem0**](https://mem0.ai/) is a memory-augmented framework designed to build intelligent agents with contextual awareness. It allows developers to effortlessly store and retrieve conversational memories. Now with **Groq** integration, agents can harness blazing-fast, LPU-powered LLMs for ultra-responsive experiences.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Persistent Memory** : Store chat history, contextual information, and metadata for long-term recall.\n",
    "\n",
    "- **Groq-Powered LLMs** : Leverage ultra-fast models like `llama3-70b-8192` with minimal latency, thanks to Groq's LPU acceleration.\n",
    "\n",
    "- **Flexible Configuration** : Easily switch between different LLM providers and customize model parameters to fit your needs.\n",
    "\n",
    "- **Semantic Search** : Retrieve relevant memories using OpenAI embeddings for enhanced response accuracy.\n",
    "\n",
    "Let's get started with the example!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mem0ai groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set the API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"  # Used for embeddings â€“ Mem0 supports Gemini, HuggingFace, and more.\n",
    "os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Groq-backed Memory instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mem0 import Memory\n",
    "\n",
    "# Configuration for Groq-backed LLM\n",
    "config = {\n",
    "    \"llm\": {\n",
    "        \"provider\": \"groq\",\n",
    "        \"config\": {\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize Memory\n",
    "m = Memory.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ **How it works**\n",
    "\n",
    "Mem0 uses the LLM (via Groq) to process and structure memory, such as turning conversations into memory items or updating existing ones. The framework handles memory operations like storing, retrieving, and filtering user context, and is designed to be independent of response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add messages to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"How about a thriller movie? They can be quite engaging.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Iâ€™m not a big fan of thrillers but I love sci-fi movies.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\"}\n",
    "]\n",
    "\n",
    "m.add(messages, user_id=\"alice\", metadata={\"category\": \"movies\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Search memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = m.search(\"Which movie should I watch?\", user_id=\"alice\")\n",
    "\n",
    "for memory in results[\"results\"]:\n",
    "    print(memory[\"memory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [**Mem0 + Groq Integration Guide**]((https://docs.mem0.ai/components/llms/models/groq)) : Learn how to configure and run Mem0 with Groq-backed LLMs for ultra-low latency \n",
    "\n",
    "- [**Understanding Memory in Mem0**](https://docs.mem0.ai/core-concepts/memory-operations) : Dive into how memory is stored, retrieved, and managed in Mem0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
