{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dad247",
   "metadata": {},
   "source": [
    "# Groq + Firecrawl MCP: AI-Powered Web Scraping & Data Extraction\n",
    "This notebook demonstrates how to empower Groq inference with enterprise-grade web scraping capabilities using Firecrawl's Model Context Protocol (MCP) server for intelligent data extraction, structured parsing, and deep web research.\n",
    "\n",
    "We will achieve this through three simple steps:\n",
    "1. Set up **Groq MCP client** for fast inference.\n",
    "2. Set up **Firecrawl MCP server** for enterprise web scraping.\n",
    "3. Seamlessly **connect the client to the server** through the Responses API.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b1c6b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.108.1)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: ipython in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (9.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: decorator in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from jedi>=0.16->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/aalthukair/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "%pip install openai python-dotenv ipython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d57e0",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "1. **Sign up** for Groq at [console.groq.com](https://console.groq.com/keys) to get your free API key.\n",
    "2. **Sign up** for Firecrawl at [firecrawl.dev/app/api-keys](https://firecrawl.dev/app/api-keys) to get your API key.\n",
    "3. **Copy your API keys** from your Groq and Firecrawl account dashboards.\n",
    "4. **Paste your API keys** into the cell below and run the cell.\n",
    "\n",
    "*Note: do **not** run the cell below if your keys are already configured in an .env file in this directory*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cd2b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API keys into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"GROQ_API_KEY=<your-groq-api-key>\" >> .env\n",
    "!echo \"FIRECRAWL_API_KEY=<your-firecrawl-api-key>\" >> .env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3da8da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API key configured successfully!\n",
      "Firecrawl API key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types import responses as openai_responses\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "FIRECRAWL_API_KEY = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Please set your Groq API key\")\n",
    "else:\n",
    "    print(\"Groq API key configured successfully!\")\n",
    "if not FIRECRAWL_API_KEY:\n",
    "    print(\"Please set your Firecrawl API key\")\n",
    "else:\n",
    "    print(\"Firecrawl API key configured successfully!\")\n",
    "    \n",
    "MODEL = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74723f",
   "metadata": {},
   "source": [
    "## Step 1: Set up the Groq client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0315ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(base_url=\"https://api.groq.com/api/openai/v1\", api_key=GROQ_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8b94b",
   "metadata": {},
   "source": [
    "## Step 2: Set up Firecrawl's remote MCP server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42b3e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Firecrawl MCP server\n",
    "tools = [\n",
    "    openai_responses.tool_param.Mcp(\n",
    "        server_label=\"firecrawl\",\n",
    "        server_url=f\"https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/sse\",\n",
    "        type=\"mcp\",\n",
    "        require_approval=\"never\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b672a",
   "metadata": {},
   "source": [
    "## Step 3: Connect Groq to the Firecrawl MCP through Groq's Responses API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14893b",
   "metadata": {},
   "source": [
    "This will be our **main** function we use to call the Groq API. It's been formatted to give us slightly more information into how MCPs work and their efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9569e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_groq_with_tools(client, tools, query):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "        tools=tools,\n",
    "        stream=False,\n",
    "        temperature=0.1,\n",
    "        top_p=0.4,\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    content = (\n",
    "        response.output_text if hasattr(response, \"output_text\") else str(response)\n",
    "    )\n",
    "\n",
    "    executed_tools = []\n",
    "\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"type\") and output_item.type == \"mcp_call\":\n",
    "                executed_tools.append(\n",
    "                    {\n",
    "                        \"type\": \"mcp\",\n",
    "                        \"arguments\": getattr(output_item, \"arguments\", \"{}\"),\n",
    "                        \"output\": getattr(output_item, \"output\", \"\"),\n",
    "                        \"name\": getattr(output_item, \"name\", \"\"),\n",
    "                        \"server_label\": getattr(output_item, \"server_label\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "    return {\n",
    "        \"content\": content,\n",
    "        \"total_time\": total_time,\n",
    "        \"mcp_calls_performed\": executed_tools,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8208da",
   "metadata": {},
   "source": [
    "Let's implement a helper function to display MCP tool calls and their results. This will provide transparency into which tools were called, their arguments, and outputs. \n",
    "\n",
    "(This is generally useful when debugging if you need to view raw MCP outputs, it's not vital for functionality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "953dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mcp_calls(mcp_calls):\n",
    "    executed_tools = mcp_calls[\"mcp_calls_performed\"]\n",
    "    if executed_tools:\n",
    "        print(f\"\\nFIRECRAWL MCP CALLS: Found {len(executed_tools)} tool call(s):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, tool in enumerate(executed_tools, 1):\n",
    "            print(f\"\\nTool Call #{i}\")\n",
    "            print(f\"   Type: {tool['type']}\")\n",
    "            print(f\"   Tool Name: {tool['name']}\")\n",
    "            print(f\"   Server: {tool['server_label']}\")\n",
    "            try:\n",
    "                if tool[\"arguments\"]:\n",
    "                    args = (\n",
    "                        json.loads(tool[\"arguments\"])\n",
    "                        if isinstance(tool[\"arguments\"], str)\n",
    "                        else tool[\"arguments\"]\n",
    "                    )\n",
    "                    print(f\"   Arguments: {args}\")\n",
    "\n",
    "                if tool[\"output\"]:\n",
    "                    output_data = (\n",
    "                        json.loads(tool[\"output\"])\n",
    "                        if isinstance(tool[\"output\"], str)\n",
    "                        else tool[\"output\"]\n",
    "                    )\n",
    "                    if isinstance(output_data, dict):\n",
    "                        if \"url\" in output_data:\n",
    "                            print(f\"   URL Scraped: {output_data['url']}\")\n",
    "                        if \"success\" in output_data:\n",
    "                            print(f\"   Success: {output_data['success']}\")\n",
    "                        if \"markdown\" in output_data:\n",
    "                            content_preview = output_data[\"markdown\"][:200] + \"...\" if len(output_data[\"markdown\"]) > 200 else output_data[\"markdown\"]\n",
    "                            print(f\"   Content Preview: {content_preview}\")\n",
    "                    else:\n",
    "                        print(f\"   Output: {str(output_data)[:200]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Could not parse tool data: {e}\")\n",
    "    print(f\"   Total time: {mcp_calls['total_time']:.2f} seconds\")\n",
    "    print(f\"   Firecrawl MCP calls: {len(mcp_calls['mcp_calls_performed'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62ff3c",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "**Note:** Some queries may consume more tokens than others depending on the amount of tool calls the model makes. Please be aware of various rate limits that are tied to your API keys if you happen to run into any rate limit errors. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e977c5",
   "metadata": {},
   "source": [
    "## Demo 1: Website Analysis & Content Scraping\n",
    "\n",
    "Let's build a web scraper that analyzes Anthropic's website to extract comprehensive company information, products, and recent announcements using Firecrawl's intelligent scraping capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d78212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "website_analysis = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"Scrape and analyze the website https://anthropic.com. Provide a comprehensive overview of what the company does, their main products/services, key features, and any recent announcements.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca4b43",
   "metadata": {},
   "source": [
    "Let's display the agent's response in markdown format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(website_analysis[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49e5f4",
   "metadata": {},
   "source": [
    "Let's examine the agent's intermediate steps, including how it calls different Firecrawl tools and configures tool arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(website_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caabea6d",
   "metadata": {},
   "source": [
    "## Demo 2: Structured Data Extraction\n",
    "\n",
    "Now we'll create a competitive analysis tool that extracts structured pricing data from multiple AI companies (OpenAI, Anthropic, Groq) and formats it into consistent JSON schemas for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_extraction = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"\"\"Use the firecrawl_extract tool to extract structured pricing information from these AI company websites:\n",
    "    \n",
    "    URLs: https://openai.com, https://anthropic.com, https://groq.com\n",
    "    \n",
    "    Extract the following data for each company in JSON format:\n",
    "    {\n",
    "        \"company_name\": \"string\",\n",
    "        \"pricing_plans\": [\n",
    "            {\n",
    "                \"plan_name\": \"string\",\n",
    "                \"price\": \"string\",\n",
    "                \"features\": [\"string\"]\n",
    "            }\n",
    "        ],\n",
    "        \"contact_info\": \"string\",\n",
    "        \"main_product\": \"string\"\n",
    "    }\n",
    "    \n",
    "    Focus on finding current pricing information and structure it consistently across all companies.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bb9da",
   "metadata": {},
   "source": [
    "Let's display the structured extraction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(structured_extraction[\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294eb59b",
   "metadata": {},
   "source": [
    "Let's examine the agent's intermediate steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(structured_extraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac88c1",
   "metadata": {},
   "source": [
    "## Demo 3: Deep Research & Multi-hop Analysis\n",
    "\n",
    "Here we'll build an AI research agent that conducts comprehensive multi-hop research on AI inference trends, automatically discovering and analyzing multiple sources to create a detailed research report with proper citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44071aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_research = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"\"\"Conduct comprehensive deep research on \"latest trends in AI model inference speed and performance\" using the firecrawl_deep_research tool.\n",
    "    \n",
    "    Research should include:\n",
    "    1. Recent developments in AI inference optimization (2024-2025)\n",
    "    2. Key companies and technologies leading this space\n",
    "    3. Performance benchmarks and comparison data\n",
    "    4. Future trends and implications\n",
    "    \n",
    "    Use deep research capabilities to find and analyze multiple authoritative sources. Provide a comprehensive report with proper citations.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a9c96",
   "metadata": {},
   "source": [
    "Let's display the deep research report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(deep_research[\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb207603",
   "metadata": {},
   "source": [
    "Let's examine the deep research process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d458def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(deep_research)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10de3e4",
   "metadata": {},
   "source": [
    "## Demo 4: Try it Yourself\n",
    "\n",
    "Now it's your turn! Create your own custom web intelligence agent by replacing the query below with your specific web scraping, data extraction, or research task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_query = \"Your Query Here\"  # Change this!\n",
    "\n",
    "custom_response = call_groq_with_tools(client, tools, your_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85724a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(custom_response[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a88081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(custom_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd591d17",
   "metadata": {},
   "source": [
    "## Available Firecrawl MCP Tools\n",
    "\n",
    "Firecrawl MCP provides several powerful tools for web scraping, data extraction, and research:\n",
    "\n",
    "| Tool | Description |\n",
    "|------|-------------|\n",
    "| **`firecrawl_scrape`** | Scrape content from a single URL with advanced options and formatting |\n",
    "| **`firecrawl_batch_scrape`** | Scrape multiple URLs efficiently with built-in rate limiting and parallel processing |\n",
    "| **`firecrawl_check_batch_status`** | Check the status of a batch operation and retrieve results |\n",
    "| **`firecrawl_search`** | Search the web and optionally extract content from search results |\n",
    "| **`firecrawl_crawl`** | Start an asynchronous crawl with advanced options for depth and link following |\n",
    "| **`firecrawl_extract`** | Extract structured information from web pages using LLM capabilities and JSON schemas |\n",
    "| **`firecrawl_deep_research`** | Conduct comprehensive deep web research with intelligent crawling and LLM analysis |\n",
    "| **`firecrawl_generate_llmstxt`** | Generate standardized llms.txt files that define how LLMs should interact with a site |\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Enterprise-Grade Reliability**: Handles JavaScript, authentication, and dynamic content\n",
    "2. **AI-Powered Intelligence**: Understands content semantically, not just structurally  \n",
    "3. **Batch Processing**: Efficient parallel operations for production workloads\n",
    "4. **Speed**: Sub-10 second responses when combined with Groq's fast inference\n",
    "5. **Transparency**: Full visibility into tool calls and data sources\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've just experienced fast AI-powered web intelligence that combines:\n",
    "- **Fast responses** (3-10 seconds) via Groq inference\n",
    "- **Enterprise web scraping** with Firecrawl's advanced capabilities  \n",
    "- **Structured data extraction** using AI-powered parsing\n",
    "- **Deep research** with multi-hop reasoning and source transparency\n",
    "\n",
    "This approach enables you to build applications that need both speed and reliability for web data collection and analysis tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
