{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq + HuggingFace MCP: Real-Time Model Discovery with Text-to-Speech\n",
    "**The Problem:** Finding the right model for your application usually means manually browsing lists, missing trending models, or relying on stale training data from large language models.\n",
    "\n",
    "**The Solution:** Reviewing this tutorial to learn how to combine Groq's fast inference with HuggingFace's Model Context Protocol (MCP) server to discover, analyze, and get insights about recently published models and datasets available on HuggingFace in real-time.\n",
    "\n",
    "## What is MCP and Why Does It Matter?\n",
    "MCP is a standardized way for large language models to connect with external data sources and tools. Think of it as a universal adapter that lets your model:\n",
    "- Access real-time data from APIs\n",
    "- Extend model capabilities beyond training data\n",
    "- Perform actions\n",
    "\n",
    "You can view the HuggingFace MCP server [here](https://huggingface.co/settings/mcp) to learn more about the built-in tools you can access by equipping your model with the server as we'll see below.\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Groq + HuggingFace MCP Demo\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set API Keys\n",
    "\n",
    "Here we will set the API keys for the Groq and HuggingFace APIs via either environment variables or a userdata object in Google Colab.\n",
    "\n",
    "- You can get your Groq API key from [here](https://console.groq.com/keys)\n",
    "- You can get your HuggingFace token from [here](https://huggingface.co/settings/tokens)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API key and HuggingFace token configured successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    GROQ_API_KEY = userdata.get(\"GROQ_API_KEY\")\n",
    "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
    "except ImportError:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Check if API key is set\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Please set your Groq API key:\")\n",
    "elif not HF_TOKEN:\n",
    "    print(\"Please set your HuggingFace token:\")\n",
    "else:\n",
    "    print(\"Groq API key and HuggingFace token configured successfully!\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Function: HuggingFace Model Discovery with Groq's Responses API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will use the Groq + HuggingFace MCP integration to discover trending models on HuggingFace and report the results and tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_huggingface_models(query):\n",
    "    \"\"\"\n",
    "    Discover trending models on HuggingFace using Groq + HuggingFace MCP\n",
    "\n",
    "    This function demonstrates the speed and accuracy of combining:\n",
    "    - Groq's fast LLM inference (500+ tokens/second)\n",
    "    - HuggingFace MCP server for real-time model discovery\n",
    "    \"\"\"\n",
    "\n",
    "    if not GROQ_API_KEY:\n",
    "        print(\"Please set your Groq API key first!\")\n",
    "        return\n",
    "\n",
    "    client = OpenAI(base_url=\"https://api.groq.com/api/openai/v1\", api_key=GROQ_API_KEY)\n",
    "\n",
    "    print(f\"{query}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Configure MCP tools using HuggingFace server\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_url\": \"https://huggingface.co/mcp\",\n",
    "            \"server_label\": \"huggingface\",\n",
    "            \"require_approval\": \"never\",\n",
    "            \"headers\": {\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call Groq with HuggingFace MCP integration using responses API\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "        tools=tools,\n",
    "        stream=False,\n",
    "        temperature=0.1,  # Low temperature for consistent tool calling\n",
    "        top_p=0.4,  # Balanced top_p for focused but flexible responses\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Get response content from responses API format\n",
    "    content = (\n",
    "        response.output_text if hasattr(response, \"output_text\") else str(response)\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"HUGGINGFACE MODEL DISCOVERY RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(content)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Show executed tools (MCP tool calls) for transparency\n",
    "    executed_tools = []\n",
    "\n",
    "    # Extract MCP calls from response if available\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"type\") and output_item.type == \"mcp_call\":\n",
    "                executed_tools.append(\n",
    "                    {\n",
    "                        \"type\": \"mcp\",\n",
    "                        \"arguments\": getattr(output_item, \"arguments\", \"{}\"),\n",
    "                        \"output\": getattr(output_item, \"output\", \"\"),\n",
    "                        \"name\": getattr(output_item, \"name\", \"\"),\n",
    "                        \"server_label\": getattr(output_item, \"server_label\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if executed_tools:\n",
    "        print(f\"\\nHUGGINGFACE MCP CALLS: Found {len(executed_tools)} tool calls:\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for i, tool in enumerate(executed_tools, 1):\n",
    "            print(f\"\\nTool Call #{i}\")\n",
    "            print(f\"   Type: {tool['type']}\")\n",
    "            print(f\"   Tool Name: {tool['name']}\")\n",
    "            print(f\"   Server: {tool['server_label']}\")\n",
    "            try:\n",
    "                if tool[\"arguments\"]:\n",
    "                    args = (\n",
    "                        json.loads(tool[\"arguments\"])\n",
    "                        if isinstance(tool[\"arguments\"], str)\n",
    "                        else tool[\"arguments\"]\n",
    "                    )\n",
    "                    print(f\"   Arguments: {args}\")\n",
    "\n",
    "                # Print model results for transparency\n",
    "                if tool[\"output\"]:\n",
    "                    output_data = (\n",
    "                        json.loads(tool[\"output\"])\n",
    "                        if isinstance(tool[\"output\"], str)\n",
    "                        else tool[\"output\"]\n",
    "                    )\n",
    "                    if isinstance(output_data, dict) and \"models\" in output_data:\n",
    "                        print(f\"   Models found: {len(output_data['models'])}\")\n",
    "                        for j, model in enumerate(\n",
    "                            output_data[\"models\"][:5], 1\n",
    "                        ):  # Show top 5\n",
    "                            model_name = model.get(\"id\", model.get(\"name\", \"Unknown\"))\n",
    "                            print(f\"      {j}. {model_name}\")\n",
    "                        if len(output_data[\"models\"]) > 5:\n",
    "                            print(\n",
    "                                f\"      ... and {len(output_data['models']) - 5} more models\"\n",
    "                            )\n",
    "                    else:\n",
    "                        print(f\"   Output: {str(output_data)[:200]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Could not parse tool data: {e}\")\n",
    "\n",
    "    # Performance summary\n",
    "    print(f\"\\nPERFORMANCE SUMMARY\")\n",
    "    print(f\"   Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"   HuggingFace MCP calls: {len(executed_tools)}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nNote: This speed comes from fast inference + HuggingFace MCP integration!\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"content\": content,\n",
    "        \"total_time\": total_time,\n",
    "        \"mcp_calls_performed\": len(executed_tools),\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Discover Top Trending Models on HuggingFace\n",
    "\n",
    "Let's start by finding the top trending models on HuggingFace to see the speed and accuracy in action. \n",
    "\n",
    "**What to watch for:**\n",
    "- **Speed**: Response time with Groq + HuggingFace MCP \n",
    "- **Real-time data**: Current trending models and popularity metrics  \n",
    "- **Fresh information**: Model data that's more recent than traditional LLM training data\n",
    "- **Tool transparency**: See exactly which HuggingFace MCP tools were called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find the top trending model on HuggingFace and tell me about it, use groq_play_tts to speak.\n",
      "================================================================================\n",
      "HUGGINGFACE MODEL DISCOVERY RESULTS\n",
      "================================================================================\n",
      "**Top‑Trending Hugging Face Model (as of now)**  \n",
      "**Model:** `tencent/SRPO`  \n",
      "**Task:** Text‑to‑Image generation  \n",
      "**Library:** Diffusers (uses `safetensors` format)  \n",
      "**Created:** 8 Sep 2025 | **Last updated:** 15 Sep 2025  \n",
      "**Downloads:** ≈ 5.8 K | **Likes:** ≈ 829 | **Trending score:** 779  \n",
      "\n",
      "### What it does\n",
      "SRPO (Stable‑Diffusion‑style **S**uper‑Resolution **R**econstruction **P**rompt‑Optimized) is a state‑of‑the‑art text‑to‑image diffusion model released by Tencent. It builds on the latest research (see arXiv 2509.06942) and is optimized for:\n",
      "\n",
      "* **High‑fidelity image synthesis** from natural language prompts.  \n",
      "* **Fast inference** thanks to the efficient `safetensors` checkpoint format.  \n",
      "* **Versatile style control** – works well for photorealistic, artistic, and stylized outputs.  \n",
      "\n",
      "### Key features\n",
      "| Feature | Details |\n",
      "|---------|---------|\n",
      "| **Model architecture** | Diffusion model compatible with the 🤗 Diffusers pipeline. |\n",
      "| **Checkpoint format** | `safetensors` (memory‑efficient, no Python code execution on load). |\n",
      "| **License** | “Other” – check the model card for usage restrictions. |\n",
      "| **Demo Spaces** | • [SRPO Playground](https://hf.co/spaces/akhaliq/SRPO)  <br>• [searchgpt](https://hf.co/spaces/umint/searchgpt)  <br>• [image](https://hf.co/spaces/umint/image) |\n",
      "| **Inference providers** | Available via **fal‑ai** (staging) for API‑based generation. |\n",
      "| **How to try it** | Use the built‑in playground: <https://hf.co/playground?modelId=tencent/SRPO> or load it in a Python script with `diffusers`:\n",
      "\n",
      "```python\n",
      "from diffusers import DiffusionPipeline\n",
      "pipe = DiffusionPipeline.from_pretrained(\n",
      "    \"tencent/SRPO\",\n",
      "    torch_dtype=\"auto\",\n",
      "    variant=\"fp16\"\n",
      ")\n",
      "pipe.to(\"cuda\")\n",
      "image = pipe(\"a futuristic city at sunset, ultra‑realistic\").images[0]\n",
      "image.save(\"output.png\")\n",
      "```\n",
      "\n",
      "### Why it’s trending\n",
      "- **Performance:** Benchmarks show SRPO surpasses many contemporaries in both image quality (higher FID/IS scores) and speed.  \n",
      "- **Community buzz:** Rapid adoption in creative‑AI projects, art generation, and rapid‑prototyping tools.  \n",
      "- **Tencent backing:** Strong engineering resources and frequent updates keep the model at the cutting edge.\n",
      "\n",
      "**Link:** <https://hf.co/tencent/SRPO>\n",
      "\n",
      "---\n",
      "\n",
      "*If you’d like this summary spoken aloud, you can feed the text to a TTS system such as `groq_play_tts`.*\n",
      "================================================================================\n",
      "\n",
      "HUGGINGFACE MCP CALLS: Found 2 tool calls:\n",
      "--------------------------------------------------\n",
      "\n",
      "Tool Call #1\n",
      "   Type: mcp\n",
      "   Tool Name: model_search\n",
      "   Server: huggingface\n",
      "   Arguments: {'limit': 1, 'sort': 'trendingScore'}\n",
      "   Could not parse tool data: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Tool Call #2\n",
      "   Type: mcp\n",
      "   Tool Name: model_details\n",
      "   Server: huggingface\n",
      "   Arguments: {'model_id': 'tencent/SRPO'}\n",
      "   Could not parse tool data: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "PERFORMANCE SUMMARY\n",
      "   Total time: 3.29 seconds\n",
      "   HuggingFace MCP calls: 2\n",
      "\n",
      "Note: This speed comes from fast inference + HuggingFace MCP integration!\n"
     ]
    }
   ],
   "source": [
    "# Let's discover the top trending models on HuggingFace\n",
    "# This will demonstrate both speed and real-time model discovery\n",
    "\n",
    "result_trending = discover_huggingface_models(\n",
    "    \"Find the top trending model on HuggingFace and tell me about it, use groq_play_tts to speak.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Search for Specific Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for the latest image datasets\n",
      "================================================================================\n",
      "HUGGINGFACE MODEL DISCOVERY RESULTS\n",
      "================================================================================\n",
      "Here are the **most‑recent image‑focused datasets** that have just been added to the Hugging Face Hub (sorted by creation date, newest first). All links go directly to the dataset pages where you can view the README, download files, and see usage examples.\n",
      "\n",
      "| # | Dataset (link) | Size / Category | Modality | Format | Brief description / typical use‑case | Created (UTC) |\n",
      "|---|----------------|----------------|----------|--------|--------------------------------------|---------------|\n",
      "| 1 | **[Korea‑MES/Token‑Upperbound‑Herems2.5‑fix‑800‑with‑images](https://hf.co/datasets/Korea-MES/Token-Upperbound-Herems2.5-fix-800-with-images)** | ~1 K – 10 K samples | image + text | Parquet | Token‑upperbound dataset that pairs images with token‑level annotations – useful for OCR, layout‑aware language models, and multimodal token‑level training. | 19 Sep 2025 |\n",
      "| 2 | **[svjack/Eula_Lawrence_Images_MiniCPM_V4_5_Captioned](https://hf.co/datasets/svjack/Eula_Lawrence_Images_MiniCPM_V4_5_Captioned)** | <1 K images | image + text | Parquet | Small curated set of captioned images generated with MiniCPM V4.5 – handy for quick prototyping of image‑to‑text models. | 19 Sep 2025 |\n",
      "| 3 | **[alisharifi/tourist-attractions-text-image-data](https://hf.co/datasets/alisharifi/tourist-attractions-text-image-data)** | ~1 K – 10 K pairs | image + text | Parquet | Tourist‑attraction photos with descriptive captions; good for fine‑tuning vision‑language models on travel‑related content. | 19 Sep 2025 |\n",
      "| 4 | **[svjack/Peng_UNO_Flux_Images](https://hf.co/datasets/svjack/Peng_UNO_Flux_Images)** | <1 K images | image | ImageFolder | A small collection of images generated with the Flux model (UNO variant). Useful for evaluating diffusion‑model outputs or style transfer. | 19 Sep 2025 |\n",
      "| 5 | **[mohajesmaeili/Persian_Arabic_Printed_TextLine_Image_Medium](https://hf.co/datasets/mohajesmaeili/Persian_Arabic_Printed_TextLine_Image_Medium)** | Medium‑sized (≈ 10 K) | image + text | – | Printed text‑line images in Persian & Arabic with transcriptions – ideal for OCR research on right‑to‑left scripts. | 19 Sep 2025 |\n",
      "| 6 | **[MingSafeR/anime_porn_image_1M_augmentation](https://hf.co/datasets/MingSafeR/anime_porn_image_1M_augmentation)** | 100 K – 1 M images (augmented) | image | – | Large‑scale anime‑style image collection (CC‑BY‑NC‑4.0). **Not‑for‑all‑audiences** – use only for research under the license terms. | 19 Sep 2025 |\n",
      "| 7 | **[nujiznaw/sift-image-classification](https://hf.co/datasets/nujiznaw/sift-image-classification)** | Small (≈ 500) | image | – | Classic SIFT‑based image classification dataset; good for baseline feature‑extraction experiments. | 19 Sep 2025 |\n",
      "| 8 | **[Darshanshet23/image_data](https://hf.co/datasets/Darshanshet23/image_data)** | <1 K images | image | ImageFolder | Generic folder of assorted images – a quick sandbox for testing data loaders. | 19 Sep 2025 |\n",
      "| 9 | **[Darshanshet23/images](https://hf.co/datasets/Darshanshet23/images)** | <1 K images | image | ImageFolder | Same as above (duplicate upload under a different name). | 19 Sep 2025 |\n",
      "|10| **[jomaminoza/imagenet-paired-generation](https://hf.co/datasets/jomaminoza/imagenet-paired-generation)** | Small subset of ImageNet (≈ 2 K) | image + text | – | Paired ImageNet images with generated textual descriptions; useful for quick vision‑language prototyping. | 19 Sep 2025 |\n",
      "\n",
      "### How to explore further\n",
      "* **Filtering by task** – If you need datasets specifically for *image classification*, *object detection*, *image‑to‑text*, or *OCR*, let me know and I can run a more targeted search (e.g., `task:\"image-classification\"`).\n",
      "* **More results** – The Hub contains many more image datasets; I can increase the result count or sort by *downloads* or *likes* if you prefer popularity over recency.\n",
      "* **Details on a particular dataset** – I can fetch the full README, sample code snippets, or licensing information for any entry above.\n",
      "\n",
      "Just tell me what you’d like to dive into next!\n",
      "================================================================================\n",
      "\n",
      "HUGGINGFACE MCP CALLS: Found 1 tool calls:\n",
      "--------------------------------------------------\n",
      "\n",
      "Tool Call #1\n",
      "   Type: mcp\n",
      "   Tool Name: dataset_search\n",
      "   Server: huggingface\n",
      "   Arguments: {'limit': 10, 'query': 'image', 'sort': 'createdAt'}\n",
      "   Could not parse tool data: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "PERFORMANCE SUMMARY\n",
      "   Total time: 3.82 seconds\n",
      "   HuggingFace MCP calls: 1\n",
      "\n",
      "Note: This speed comes from fast inference + HuggingFace MCP integration!\n"
     ]
    }
   ],
   "source": [
    "result_image_datasets = discover_huggingface_models(\n",
    "    \"Search for the latest image datasets\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis: Why This Combination Works Well\n",
    "\n",
    "Let's analyze what just happened and why Groq + HuggingFace MCP is effective:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE BREAKDOWN\n",
      "==================================================\n",
      "\n",
      "Top Trending Models Discovery:\n",
      "   Time: 3.29 seconds\n",
      "   MCP Calls: 2\n",
      "   Response length: 2336 characters\n",
      "\n",
      "AVERAGES:\n",
      "   Average response time: 3.29 seconds\n",
      "   Average MCP calls per query: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze the performance from our model discovery sessions\n",
    "print(\"PERFORMANCE BREAKDOWN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = []\n",
    "if \"result_trending\" in locals() and result_trending:\n",
    "    results.append((\"Top Trending Models\", result_trending))\n",
    "if \"result_cv_models\" in locals() and result_image_datasets:\n",
    "    results.append((\"Image Datasets\", result_image_datasets))\n",
    "\n",
    "\n",
    "if results:\n",
    "    for query_name, result in results:\n",
    "        print(f\"\\n{query_name} Discovery:\")\n",
    "        print(f\"   Time: {result['total_time']:.2f} seconds\")\n",
    "        print(f\"   MCP Calls: {result['mcp_calls_performed']}\")\n",
    "        print(f\"   Response length: {len(result['content'])} characters\")\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_time = sum(r[1][\"total_time\"] for r in results) / len(results)\n",
    "    avg_mcp_calls = sum(r[1][\"mcp_calls_performed\"] for r in results) / len(results)\n",
    "\n",
    "    print(\"\\nAVERAGES:\")\n",
    "    print(f\"   Average response time: {avg_time:.2f} seconds\")\n",
    "    print(f\"   Average MCP calls per query: {avg_mcp_calls:.1f}\")\n",
    "\n",
    "else:\n",
    "    print(\"No results to analyze yet. Run the model discovery cells above first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just witnessed MCP - where models are equipped with tools and autonomously decide when to execute functions during generation. The model doesn't just generate text; it actively calls APIs and interacts with external systems, as demonstrated with HuggingFace's MCP server that includes tools such as model search, dataset search, and more.\n",
    "\n",
    "Speed matters because models make real-time decisions about tool usage, often triggering multiple function calls per response. Groq's fast inference makes tool-enabled models feel instantaneous.\n",
    "The HuggingFace integration here is just one example. MCP works with any tools - databases, APIs, file systems. Ready to build AI features that act, not just talk? We are too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
