{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104f2b97-f9bb-4dcc-a4c8-099710768851",
   "metadata": {},
   "source": [
    "# Streaming Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc57b6-2c48-4ee3-bb2c-25441274ed2f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70814b4",
   "metadata": {},
   "source": [
    "Make sure you have `ipykernel` and `pip` pre-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962ae5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from groq->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/rick/workspace/groq-api-cookbook/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq->-r requirements.txt (line 1)) (2.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21816b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Groq API key configured: gsk_7FdrzM...'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\"Groq API key configured: \" + os.environ[\"GROQ_API_KEY\"][:10] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c9c55-e925-4cc1-89f2-58237acf14a4",
   "metadata": {},
   "source": [
    "We will use the ```llama3-70b-8192``` model in this demo. Note that you will need a Groq API Key to proceed and can create an account [here](https://console.groq.com/) to generate one for free. Only Llama 3 models support parallel tool use at this time (05/07/2024).\n",
    "\n",
    "We recommend using the 70B Llama 3 model, 8B has subpar consistency.\n",
    "\n",
    "Please note that in this notebook we show how to deal with chunks that are provided by the client SDK directly. For many frameworks that support streaming tool calling like LangChain, this low-level handling is not required, you can simply enable streaming support.\n",
    "\n",
    "This tutorial is useful if you want more control and understand lower level details of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cca781b-1950-4167-b36a-c1099d6b3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "model = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23ec2b",
   "metadata": {},
   "source": [
    "Let's define a dummy function we can invoke in our tool use loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ce18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str):\n",
    "    if city == \"Madrid\":\n",
    "        return 35\n",
    "    elif city == \"San Francisco\":\n",
    "        return 18\n",
    "    elif city == \"Paris\":\n",
    "        return 20\n",
    "    else:\n",
    "        return 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e3c92",
   "metadata": {},
   "source": [
    "Now we define our messages and tools and run the completion request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b454910-4352-40cc-b9b2-cc79edabd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are a helpful assistant.\"\"\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather in Paris, Tokyo and Madrid?\",\n",
    "    },\n",
    "]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Returns the weather in the given city in degrees Celsius\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096, stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885bac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resp_to_result(response):\n",
    "    tool_calls = []\n",
    "    tool_call_buffers = {}\n",
    "    content_response = \"\"\n",
    "\n",
    "    for chunk in response:\n",
    "        print(chunk)\n",
    "        for choice in chunk.choices:\n",
    "            if choice.delta.tool_calls:\n",
    "                for tool_call in choice.delta.tool_calls:\n",
    "                    index = tool_call.index\n",
    "                    if index not in tool_call_buffers:\n",
    "                        tool_call_buffers[index] = {\n",
    "                            \"id\": tool_call.id,\n",
    "                            \"type\": tool_call.type,\n",
    "                            \"function\": {\n",
    "                                \"arguments\": \"\",\n",
    "                                \"name\": \"\"\n",
    "                            }\n",
    "                        }\n",
    "                    if tool_call.function.arguments is not None:\n",
    "                        tool_call_buffers[index][\"function\"][\"arguments\"] += tool_call.function.arguments\n",
    "                    if tool_call.function.name is not None:\n",
    "                        tool_call_buffers[index][\"function\"][\"name\"] += tool_call.function.name\n",
    "            elif choice.delta.content:\n",
    "                content_response += choice.delta.content\n",
    "\n",
    "    tool_calls = list(tool_call_buffers.values())\n",
    "    \n",
    "    if tool_calls:\n",
    "        return tool_calls\n",
    "    else:\n",
    "        return content_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d98c63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-14f9b8e2-0b43-4587-b3c5-9274cbd9c658', choices=[Choice(delta=ChoiceDelta(content='', role='assistant', function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471247, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint=None, x_groq=XGroq(usage=None, id='req_01hyjthc9rfz2t31hma8xwj8kj'))\n",
      "ChatCompletionChunk(id='chatcmpl-14f9b8e2-0b43-4587-b3c5-9274cbd9c658', choices=[Choice(delta=ChoiceDelta(content=None, role=None, function_call=None, tool_calls=[ChoiceDeltaToolCall(index=0, id='call_h53x', function=ChoiceDeltaToolCallFunction(arguments='{\"city\":\"Paris\"}', name='get_weather'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1716471247, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_753a4aecf6', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-14f9b8e2-0b43-4587-b3c5-9274cbd9c658', choices=[Choice(delta=ChoiceDelta(content=None, role=None, function_call=None, tool_calls=[ChoiceDeltaToolCall(index=1, id='call_2nr3', function=ChoiceDeltaToolCallFunction(arguments='{\"city\":\"Tokyo\"}', name='get_weather'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1716471247, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_753a4aecf6', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-14f9b8e2-0b43-4587-b3c5-9274cbd9c658', choices=[Choice(delta=ChoiceDelta(content=None, role=None, function_call=None, tool_calls=[ChoiceDeltaToolCall(index=2, id='call_4py5', function=ChoiceDeltaToolCallFunction(arguments='{\"city\":\"Madrid\"}', name='get_weather'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1716471247, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_753a4aecf6', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-14f9b8e2-0b43-4587-b3c5-9274cbd9c658', choices=[Choice(delta=ChoiceDelta(content=None, role=None, function_call=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1716471247, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_753a4aecf6', x_groq=XGroq(usage=Usage(completion_time=0.387109752, completion_tokens=121, prompt_time=0.213729859, prompt_tokens=934, queue_time=0.08143180000000003, total_time=0.6008396109999999, total_tokens=1055), id='req_01hyjthc9rfz2t31hma8xwj8kj'))\n"
     ]
    }
   ],
   "source": [
    "tool_calls = resp_to_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf3200f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_h53x',\n",
       "  'type': 'function',\n",
       "  'function': {'arguments': '{\"city\":\"Paris\"}', 'name': 'get_weather'}},\n",
       " {'id': 'call_2nr3',\n",
       "  'type': 'function',\n",
       "  'function': {'arguments': '{\"city\":\"Tokyo\"}', 'name': 'get_weather'}},\n",
       " {'id': 'call_4py5',\n",
       "  'type': 'function',\n",
       "  'function': {'arguments': '{\"city\":\"Madrid\"}', 'name': 'get_weather'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2838f",
   "metadata": {},
   "source": [
    "# Processing the tool calls\n",
    "\n",
    "Now we process the assistant message and construct the required messages to continue the conversation. \n",
    "\n",
    "*Including* invoking each tool_call against our actual function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe623ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You are a helpful assistant.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the weather in Paris, Tokyo and Madrid?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_h53x\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Paris\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_2nr3\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Tokyo\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_4py5\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Madrid\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_h53x\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Paris\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_2nr3\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Tokyo\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_4py5\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Madrid\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_h53x\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Paris\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_2nr3\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Tokyo\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"call_4py5\",\n",
      "        \"function\": {\n",
      "          \"name\": \"get_weather\",\n",
      "          \"arguments\": \"{\\\"city\\\":\\\"Madrid\\\"}\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"content\": \"20\",\n",
      "    \"tool_call_id\": \"call_h53x\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"content\": \"15\",\n",
      "    \"tool_call_id\": \"call_2nr3\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"content\": \"35\",\n",
      "    \"tool_call_id\": \"call_4py5\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": tool_call[\"id\"],\n",
    "                \"function\": {\n",
    "                    \"name\": tool_call[\"function\"][\"name\"],\n",
    "                    \"arguments\": tool_call[\"function\"][\"arguments\"],\n",
    "                },\n",
    "                \"type\": tool_call[\"type\"],\n",
    "            }\n",
    "            for tool_call in tool_calls\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "}\n",
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call[\"function\"][\"name\"]\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    # Note how we create a separate tool call message for each tool call\n",
    "    # the model is able to discern the tool call result through the tool_call_id\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(function_response),\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(json.dumps(messages, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe981a",
   "metadata": {},
   "source": [
    "Now we run our final completion with multiple tool call results included in the messages array.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We pass the tool definitions again to help the model understand:\n",
    "\n",
    "1. The assistant message with the tool call\n",
    "2. Interpret the tool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f077df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='', role='assistant', function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint=None, x_groq=XGroq(usage=None, id='req_01hyjtmk3qfrkt3wqe8ndvf8n1'))\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='The', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' weather', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' in', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' Paris', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' is', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' ', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='20', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='°C', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=',', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' in', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' Tokyo', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' is', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' ', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='15', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='°C', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=',', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' and', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' in', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' Madrid', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' is', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=' ', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='35', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='°C', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content='.', role=None, function_call=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=None)\n",
      "ChatCompletionChunk(id='chatcmpl-1f4da120-722a-4889-bc3a-c8bc6d2bde39', choices=[Choice(delta=ChoiceDelta(content=None, role=None, function_call=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1716471352, model='llama3-70b-8192', object='chat.completion.chunk', system_fingerprint='fp_c1a4bcec29', x_groq=XGroq(usage=Usage(completion_time=0.079138273, completion_tokens=24, prompt_time=0.306459267, prompt_tokens=1310, queue_time=0.060817778000000045, total_time=0.38559753999999996, total_tokens=1334), id='req_01hyjtmk3qfrkt3wqe8ndvf8n1'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in Paris is 20°C, in Tokyo is 15°C, and in Madrid is 35°C.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096, stream=True\n",
    ")\n",
    "\n",
    "text = resp_to_result(response)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
